ğŸ§  Poker AI Project Plan
Last updated: 2025-07-19
Author: AiÅ¡a Berro (for ChatGPT continuity)

ğŸ¯ Project Goal
Create a high-performing AI system that learns how to play poker (starting with No-Limit Texas Holdâ€™em) through self-play and reinforcement learning. The system will simulate different AI personalities (agents) and environments to train the ultimate poker decision-maker that can advise the user in real tournaments.

ğŸ‘©â€ğŸ’» User Profile
Name: AiÅ¡a Berro
Background: Computer Science, Frontend Developer (strong JS, some Python)
Interest: AI, Reinforcement Learning, Poker
Motivation: Personal project, not commercial.
Budget: No limit (but cautious about quality and timing of purchases)

ğŸ§  AI Agents
We are developing 4 separate AI agents, each with its own learning strategy and personality. Each will train and evolve over time:

Nashy â€“ Nash-equilibrium-based conservative agent

Bluffy â€“ Aggressive, bluffing-heavy agent

Sharky â€“ Optimal, learning-based self-improver (trained with RL)

Basey â€“ Rule-based agent with fixed, non-learning strategy (for benchmarking)

Agents will be trained in different environments and game types to evaluate their performance across various contexts (cash games, SNGs, MTTs, etc.).

ğŸ“ Folder Structure

bash
Copy
Edit
poker-ai/
â”œâ”€â”€ agents/          # Each AI agent and base class
â”‚   â”œâ”€â”€ base_agent.py
â”‚   â”œâ”€â”€ nash.py
â”‚   â”œâ”€â”€ bluffy.py
â”‚   â””â”€â”€ sharky.py
â”œâ”€â”€ engine/          # Core poker logic
â”‚   â”œâ”€â”€ game.py
â”‚   â”œâ”€â”€ player.py
â”‚   â”œâ”€â”€ cards.py
â”‚   â””â”€â”€ evaluator.py
â”œâ”€â”€ env/             # Gym-compatible training environment
â”‚   â””â”€â”€ poker_env.py
â”œâ”€â”€ train/           # Training scripts
â”‚   â””â”€â”€ train_agents.py
â”œâ”€â”€ utils/           # Logging, helpers, wrappers
â”‚   â””â”€â”€ logger.py
â”œâ”€â”€ main.py          # Script to run games or simulations
â””â”€â”€ requirements.txt
ğŸ› ï¸ Tech Stack

Python 3.11+

Stable Baselines3

OpenAI Gym

PyPokerEngine / custom engine

VS Code (optional)

macOS (initially on Intel MacBook Pro, upgrades later)

(Possibly later: CUDA/GPU training on cloud or new Mac)

âœ… Current Progress

âœ… Virtualenv created (pokerai)

âœ… Python installed

âœ… Stable Baselines3 installed

âœ… Folder structure scaffolded

âœ… Game engine implemented (cards, game flow, betting)

âœ… hand_evaluator.py working with correct ranking logic

âœ… Showdown display improved with descriptive ranks

âœ… Best 5-card hand shown per player

âŒ Agents coded

âŒ Training scripts created

âŒ Evaluation/metrics

âŒ Final advisor model

ğŸ“Œ Next Steps

Build poker_env.py for Gym compatibility

Implement base_agent.py as abstract class/interface

Define simple Basey agent as benchmark

Begin training Sharky with PPO/A2C in self-play mode

Evaluate each agent against others

Continuously refine logic and retrain

ğŸ“ Notes
This file is for ChatGPT context restoration in case of lost session/memory.
Paste it at the start of a new session to reestablish context.
Update it as the project evolves.